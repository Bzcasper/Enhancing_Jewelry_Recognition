{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification Model by CNN"
      ],
      "metadata": {
        "id": "vQjmNcg5m01m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import pickle\n",
        "\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Mounting Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "r5VTxrpBLAWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e078d831-5964-499e-ab7b-0c5f7b9a0e45"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting image to array:\n",
        "\n",
        "def img2array(path, img_size= 32):\n",
        "\n",
        "  img_array = cv2.imread(path)\n",
        "  img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB) # Convert from BGR to RGB\n",
        "\n",
        "  return cv2.resize(img_array, (img_size, img_size))\n"
      ],
      "metadata": {
        "id": "BQ35cR_cEutE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating training data and testing data:\n",
        "\n",
        "categories = ['NECKLACE', 'WRISTWATCH', 'EARRINGS', 'RINGS', 'BRACELET']\n",
        "\n",
        "def createData(dir):\n",
        "\n",
        "  data= []\n",
        "  for cat in categories:    \n",
        "    path = os.path.join(dir, cat)\n",
        "    cat_num = categories.index(cat)\n",
        "\n",
        "    for img in os.listdir(path):\n",
        "      try:\n",
        "        img_path = os.path.join(path, img)\n",
        "        array = img2array(img_path, img_size= 32)  # Calling img2array function      \n",
        "        data.append([array, cat_num])\n",
        "      except Exception as e:\n",
        "        pass\n",
        "\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "rdeEp-rUZM2c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instatiating training and testing data\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/ImageClassification/training'\n",
        "test_dir = '/content/drive/MyDrive/ImageClassification/test'\n",
        "\n",
        "training_data = createData(train_dir)\n",
        "testing_data = createData(test_dir)"
      ],
      "metadata": {
        "id": "Vyallzd5eI7s"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of training data: {len(training_data)}\\n\\nLength of testing data: {len(testing_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxuhW56yqYoy",
        "outputId": "de9d0a7c-b69d-485e-8f2e-20afbd140ca4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training data: 1564\n",
            "\n",
            "Length of testing data: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing training data and testing data:\n",
        "\n",
        "def pre_process(data, size= 32):  \n",
        "\n",
        "  '''Shuffle the training data to reduce overfitting of model'''\n",
        "  random.shuffle(data)\n",
        "\n",
        "  '''Creating variables: feature set X and labels y'''\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for feat, lab in data:\n",
        "    X.append(feat)\n",
        "    y.append(lab)\n",
        "\n",
        "  '''Converting feature set X into numpy array, so that it'll be able to pass to the neural network'''\n",
        "  X = np.array(X).reshape(-1, size, size, 3) \n",
        "  y = np.array(y)\n",
        "\n",
        "  '''Images are 8-bit value, which means it can have values between 0 and 255'''\n",
        "  '''Normalizing feature set X by scaling between 0 and 1'''\n",
        "  X = X/255.0\n",
        "\n",
        "  return X, y\n",
        "  \n"
      ],
      "metadata": {
        "id": "8NntLZaWUfR-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instatiating traing features and lables\n",
        "\n",
        "X, y = pre_process(training_data)\n",
        "\n",
        "# Instatiating testing features and lables\n",
        "\n",
        "X_test, y_test = pre_process(testing_data)"
      ],
      "metadata": {
        "id": "1a0xYVpEteb9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling training model\n",
        "\n",
        "def compile_model():\n",
        "\n",
        "  '''Instantiating sequential class of keras'''\n",
        "  model = Sequential()\n",
        "\n",
        "  '''First convolution layer'''\n",
        "  model.add(Conv2D(32, (3,3), input_shape = X.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size= (2,2)))\n",
        "\n",
        "  '''Second convolution layer'''\n",
        "  model.add(Conv2D(64, (3,3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size= (2,2)))\n",
        "\n",
        "  '''Dense layer'''\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  '''Output layer'''\n",
        "  model.add(Dense(5))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  '''Compiling model'''\n",
        "  model.compile(loss= 'sparse_categorical_crossentropy', optimizer= 'adam', metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = compile_model() # Instantiating compiled model"
      ],
      "metadata": {
        "id": "hxpDhYFdwswg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "TgXpGPOYyXq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3e7844-7224-43a7-ba63-de8955960e67"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               295040    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 315,077\n",
            "Trainable params: 315,077\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting training model\n",
        "\n",
        "def fit_model(epochs= 10, batch_size= 32):\n",
        "\n",
        "  '''Creating Model Checkpoint'''\n",
        "  file = 'final_model.h5'          \n",
        "  checkpoint = ModelCheckpoint(file, monitor = 'val_accuracy', verbose= 1, save_best_only= True, mode= 'max')\n",
        "\n",
        "  '''Fitting model''' \n",
        "  model.fit(X, y, epochs = epochs, batch_size= batch_size, validation_data = (X_test, y_test), callbacks = [checkpoint])\n",
        "\n",
        "  return model, file\n",
        "\n",
        "fit_model, final_model = fit_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQgFrL25c6gc",
        "outputId": "ad8231dd-be39-4e5c-c9a1-339a32a5143f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.9859 - accuracy: 0.6049\n",
            "Epoch 1: val_accuracy improved from -inf to 0.74000, saving model to final_model.h5\n",
            "49/49 [==============================] - 11s 13ms/step - loss: 0.9859 - accuracy: 0.6049 - val_loss: 0.7272 - val_accuracy: 0.7400\n",
            "Epoch 2/10\n",
            "42/49 [========================>.....] - ETA: 0s - loss: 0.4207 - accuracy: 0.8534\n",
            "Epoch 2: val_accuracy improved from 0.74000 to 0.82400, saving model to final_model.h5\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8613 - val_loss: 0.5534 - val_accuracy: 0.8240\n",
            "Epoch 3/10\n",
            "42/49 [========================>.....] - ETA: 0s - loss: 0.3039 - accuracy: 0.8973\n",
            "Epoch 3: val_accuracy improved from 0.82400 to 0.82800, saving model to final_model.h5\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.9003 - val_loss: 0.5811 - val_accuracy: 0.8280\n",
            "Epoch 4/10\n",
            "42/49 [========================>.....] - ETA: 0s - loss: 0.2654 - accuracy: 0.9122\n",
            "Epoch 4: val_accuracy improved from 0.82800 to 0.85200, saving model to final_model.h5\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.2547 - accuracy: 0.9169 - val_loss: 0.4914 - val_accuracy: 0.8520\n",
            "Epoch 5/10\n",
            "44/49 [=========================>....] - ETA: 0s - loss: 0.1949 - accuracy: 0.9325\n",
            "Epoch 5: val_accuracy did not improve from 0.85200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.1941 - accuracy: 0.9335 - val_loss: 0.7406 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "43/49 [=========================>....] - ETA: 0s - loss: 0.1677 - accuracy: 0.9440\n",
            "Epoch 6: val_accuracy did not improve from 0.85200\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.1605 - accuracy: 0.9482 - val_loss: 0.4729 - val_accuracy: 0.8440\n",
            "Epoch 7/10\n",
            "45/49 [==========================>...] - ETA: 0s - loss: 0.1381 - accuracy: 0.9590\n",
            "Epoch 7: val_accuracy did not improve from 0.85200\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.1367 - accuracy: 0.9584 - val_loss: 0.5132 - val_accuracy: 0.8480\n",
            "Epoch 8/10\n",
            "44/49 [=========================>....] - ETA: 0s - loss: 0.1181 - accuracy: 0.9702\n",
            "Epoch 8: val_accuracy did not improve from 0.85200\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9680 - val_loss: 0.5202 - val_accuracy: 0.8400\n",
            "Epoch 9/10\n",
            "43/49 [=========================>....] - ETA: 0s - loss: 0.0888 - accuracy: 0.9746\n",
            "Epoch 9: val_accuracy did not improve from 0.85200\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9751 - val_loss: 0.5476 - val_accuracy: 0.8520\n",
            "Epoch 10/10\n",
            "44/49 [=========================>....] - ETA: 0s - loss: 0.0829 - accuracy: 0.9773\n",
            "Epoch 10: val_accuracy did not improve from 0.85200\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9770 - val_loss: 0.4750 - val_accuracy: 0.8480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model using testing dataset:\n",
        "\n",
        "def evaluate_model():\n",
        "\n",
        "  loss, accuracy = fit_model.evaluate(X_test, y_test, 32)\n",
        "\n",
        "  print(f'\\nTesting loss: {loss}\\n\\nTesting accuracy: {accuracy}')\n",
        "\n",
        "evaluate_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPIpyfiz7miV",
        "outputId": "bbf7d717-f668-4974-f80d-f330d5fe1f38"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8480\n",
            "\n",
            "Testing loss: 0.4750211238861084\n",
            "\n",
            "Testing accuracy: 0.8479999899864197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading our final keras model from checkpoint \n",
        "\n",
        "def load():\n",
        "  return load_model(final_model)\n",
        "\n",
        "load_model = load()"
      ],
      "metadata": {
        "id": "nXJ-jksGgFzB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing new image\n",
        "\n",
        "def process_new(img_file, size):\n",
        "\n",
        "  array = img2array(img_file, img_size= size) # Calling img2array function\n",
        "  new_array = np.array(array).reshape(size, size, 3)/255.0\n",
        "  exp_array = np.expand_dims(new_array, axis=0) # Getting the expanded dimensions\n",
        "\n",
        "  return exp_array\n",
        "\n",
        "# Path of new input image\n",
        "\n",
        "image = '/content/drive/MyDrive/ImageClassification/test_img.jpg'\n",
        "\n",
        "new_array = process_new(image, size= 32) # Since, model is trained on image size = 32"
      ],
      "metadata": {
        "id": "22iSkqO6kpve"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating function to predict classification of new image\n",
        "\n",
        "def predict_class(input):\n",
        "\n",
        "  predict = load_model.predict(input)\n",
        "  \n",
        "  class_index = np.argmax(predict)\n",
        "  score = predict[0][class_index]\n",
        "\n",
        "  print(f\"\\nThis image is predicted to be of {categories[class_index]} with confidence score = {score}\")"
      ],
      "metadata": {
        "id": "6hS7MX6jSsAv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting class of new image\n",
        "\n",
        "predict_class(input = new_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ7RMHIrtQwI",
        "outputId": "7b3e2fba-0b7e-403b-8117-e6741696a57b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 161ms/step\n",
            "\n",
            "This image is predicted to be of RINGS with confidence score = 0.5311072468757629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving our final model in Drive as a pickel file\n",
        "\n",
        "def save_as_pickle(path):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(load_model, f)\n",
        "\n",
        "save_at_path = '/content/drive/MyDrive/ImageClassification/jewellery_class_cnn.pkl'\n",
        "save_as_pickle(save_at_path)"
      ],
      "metadata": {
        "id": "u4GfHavXtuV_"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}